{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7569f4f",
   "metadata": {},
   "source": [
    "# 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f1eaecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:10.415669Z",
     "start_time": "2022-07-21T15:08:08.576912Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import zipfile\n",
    "import urllib3\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Input, LSTM, Embedding, Dense, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0544c267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:11.620018Z",
     "start_time": "2022-07-21T15:08:10.416674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d78d6b",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26925c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T04:47:06.304199Z",
     "start_time": "2022-07-21T04:47:06.293065Z"
    }
   },
   "source": [
    "## 샘플 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "683cd9e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:11.635361Z",
     "start_time": "2022-07-21T15:08:11.621020Z"
    }
   },
   "outputs": [],
   "source": [
    "num_samples = 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fd98f3",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04979317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:11.651363Z",
     "start_time": "2022-07-21T15:08:11.636361Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_ascii(s):\n",
    "    # 프랑스어 악센트(accent) 삭제\n",
    "    # 예시 : 'déjà diné' -> deja dine\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(sent):\n",
    "    # 악센트 제거 함수 호출\n",
    "    sent = to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백 추가.\n",
    "    # ex) \"I am a student.\" => \"I am a student .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    # 다수 개의 공백을 하나의 공백으로 치환\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47b6b6dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:11.667367Z",
     "start_time": "2022-07-21T15:08:11.652364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 영어 문장 : Have you had dinner?\n",
      "전처리 후 영어 문장 : have you had dinner ?\n",
      "전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n",
      "전처리 후 프랑스어 문장 : avez vous deja dine ?\n"
     ]
    }
   ],
   "source": [
    "# 전처리 테스트\n",
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "\n",
    "print('전처리 전 영어 문장 :', en_sent)\n",
    "print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n",
    "print('전처리 전 프랑스어 문장 :', fr_sent)\n",
    "print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbb33d",
   "metadata": {},
   "source": [
    "## 인코더, 디코더 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2511cf57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:11.682605Z",
     "start_time": "2022-07-21T15:08:11.668611Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"D:/Dataset/dataset/parallel_corpus/fra-eng.txt\", \"r\", encoding=\"utf-8\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2adb5bb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:12.330510Z",
     "start_time": "2022-07-21T15:08:11.683604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.']]\n",
      "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.']]\n",
      "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print('인코더의 입력 :',sents_en_in[:5])\n",
    "print('디코더의 입력 :',sents_fra_in[:5])\n",
    "print('디코더의 레이블 :',sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768cd0f2",
   "metadata": {},
   "source": [
    "## 데이터 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "558a934e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:12.896239Z",
     "start_time": "2022-07-21T15:08:12.331511Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b323b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:12.907674Z",
     "start_time": "2022-07-21T15:08:12.896239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (30000, 7)\n",
      "디코더의 입력의 크기(shape) : (30000, 16)\n",
      "디코더의 레이블의 크기(shape) : (30000, 16)\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82dbde64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:12.923584Z",
     "start_time": "2022-07-21T15:08:12.907674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4380, 프랑스어 단어 집합의 크기 : 7674\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d915e",
   "metadata": {},
   "source": [
    "## 딕셔너리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94fa7724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:12.939259Z",
     "start_time": "2022-07-21T15:08:12.924584Z"
    }
   },
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word\n",
    "tar_to_index = tokenizer_fra.word_index\n",
    "index_to_tar = tokenizer_fra.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e74cb65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:12.954539Z",
     "start_time": "2022-07-21T15:08:12.940532Z"
    }
   },
   "outputs": [],
   "source": [
    "## 데이터 셔플\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8758c",
   "metadata": {},
   "source": [
    "## 훈련 / 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d9be760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:12.969542Z",
     "start_time": "2022-07-21T15:08:12.955540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 개수 : 3000\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(30000*0.1)\n",
    "print('검증 데이터의 개수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91af85a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:12.984829Z",
     "start_time": "2022-07-21T15:08:12.970542Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f04fdb49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:13.000834Z",
     "start_time": "2022-07-21T15:08:12.985831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (27000, 7)\n",
      "훈련 target 데이터의 크기 : (27000, 16)\n",
      "훈련 target 레이블의 크기 : (27000, 16)\n",
      "테스트 source 데이터의 크기 : (3000, 7)\n",
      "테스트 target 데이터의 크기 : (3000, 16)\n",
      "테스트 target 레이블의 크기 : (3000, 16)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8fe7c52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:13.016838Z",
     "start_time": "2022-07-21T15:08:13.001834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 샘플 : [  6  19 854   1   0   0   0]\n",
      "훈련 target 데이터의 샘플 : [  2  31   8  61 528   1   0   0   0   0   0   0   0   0   0   0]\n",
      "훈련 target 레이블의 샘플 : [ 31   8  61 528   1   3   0   0   0   0   0   0   0   0   0   0]\n",
      "테스트 source 데이터의 샘플 : [  2 358 350   3   1   0   0]\n",
      "테스트 target 데이터의 샘플 : [  2   4   9  23  14 285 120   1   0   0   0   0   0   0   0   0]\n",
      "테스트 target 레이블의 샘플 : [  4   9  23  14 285 120   1   3   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print('훈련 source 데이터의 샘플 :',encoder_input_train[0])\n",
    "print('훈련 target 데이터의 샘플 :',decoder_input_train[0])\n",
    "print('훈련 target 레이블의 샘플 :',decoder_target_train[0])\n",
    "print('테스트 source 데이터의 샘플 :',encoder_input_test[0])\n",
    "print('테스트 target 데이터의 샘플 :',decoder_input_test[0])\n",
    "print('테스트 target 레이블의 샘플 :',decoder_target_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4663cd8",
   "metadata": {},
   "source": [
    "# 번역기 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d620015e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:13.032841Z",
     "start_time": "2022-07-21T15:08:13.017838Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "hidden_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c4d03143",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:08:15.329960Z",
     "start_time": "2022-07-21T15:08:13.033841Z"
    }
   },
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장\n",
    "\n",
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True) \n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 모델의 입력과 출력을 정의.\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d03fca3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:10:43.375992Z",
     "start_time": "2022-07-21T15:08:15.329960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "106/106 [==============================] - 13s 48ms/step - loss: 6.9711 - acc: 0.5668 - val_loss: 2.2720 - val_acc: 0.6214\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 2.1822 - acc: 0.6206 - val_loss: 1.9846 - val_acc: 0.6345\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.9310 - acc: 0.6444 - val_loss: 1.8077 - val_acc: 0.6785\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.7736 - acc: 0.6993 - val_loss: 1.7112 - val_acc: 0.7415\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.6786 - acc: 0.7458 - val_loss: 1.6212 - val_acc: 0.7484\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.5829 - acc: 0.7498 - val_loss: 1.5364 - val_acc: 0.7604\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.5094 - acc: 0.7597 - val_loss: 1.4720 - val_acc: 0.7630\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.4383 - acc: 0.7638 - val_loss: 1.4218 - val_acc: 0.7678\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.3859 - acc: 0.7705 - val_loss: 1.3795 - val_acc: 0.7731\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.3422 - acc: 0.7766 - val_loss: 1.3399 - val_acc: 0.7810\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.2946 - acc: 0.7860 - val_loss: 1.3021 - val_acc: 0.7901\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.2558 - acc: 0.7950 - val_loss: 1.2691 - val_acc: 0.7974\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.2206 - acc: 0.8010 - val_loss: 1.2373 - val_acc: 0.8027\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.1796 - acc: 0.8073 - val_loss: 1.2094 - val_acc: 0.8047\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.1468 - acc: 0.8106 - val_loss: 1.1824 - val_acc: 0.8113\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.1108 - acc: 0.8163 - val_loss: 1.1583 - val_acc: 0.8140\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.0890 - acc: 0.8180 - val_loss: 1.1355 - val_acc: 0.8173\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.0582 - acc: 0.8216 - val_loss: 1.1149 - val_acc: 0.8193\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 1.0244 - acc: 0.8266 - val_loss: 1.0945 - val_acc: 0.8226\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.9992 - acc: 0.8296 - val_loss: 1.0765 - val_acc: 0.8248\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.9774 - acc: 0.8323 - val_loss: 1.0597 - val_acc: 0.8267\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.9525 - acc: 0.8350 - val_loss: 1.0432 - val_acc: 0.8289\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.9351 - acc: 0.8370 - val_loss: 1.0292 - val_acc: 0.8306\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.9158 - acc: 0.8387 - val_loss: 1.0155 - val_acc: 0.8326\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.8916 - acc: 0.8422 - val_loss: 1.0025 - val_acc: 0.8340\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.8725 - acc: 0.8445 - val_loss: 0.9906 - val_acc: 0.8355\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.8575 - acc: 0.8456 - val_loss: 0.9790 - val_acc: 0.8375\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.8379 - acc: 0.8478 - val_loss: 0.9684 - val_acc: 0.8374\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.8231 - acc: 0.8492 - val_loss: 0.9598 - val_acc: 0.8393\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.8009 - acc: 0.8526 - val_loss: 0.9498 - val_acc: 0.8408\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.7898 - acc: 0.8531 - val_loss: 0.9394 - val_acc: 0.8415\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.7717 - acc: 0.8554 - val_loss: 0.9318 - val_acc: 0.8425\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.7564 - acc: 0.8568 - val_loss: 0.9217 - val_acc: 0.8443\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.7413 - acc: 0.8587 - val_loss: 0.9135 - val_acc: 0.8450\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.7282 - acc: 0.8599 - val_loss: 0.9065 - val_acc: 0.8460\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.7134 - acc: 0.8621 - val_loss: 0.8988 - val_acc: 0.8462\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.6983 - acc: 0.8633 - val_loss: 0.8919 - val_acc: 0.8470\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.6860 - acc: 0.8650 - val_loss: 0.8856 - val_acc: 0.8484\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 3s 27ms/step - loss: 0.6727 - acc: 0.8669 - val_loss: 0.8787 - val_acc: 0.8495\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.6597 - acc: 0.8682 - val_loss: 0.8722 - val_acc: 0.8493\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.6483 - acc: 0.8696 - val_loss: 0.8666 - val_acc: 0.8499\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.6391 - acc: 0.8698 - val_loss: 0.8611 - val_acc: 0.8511\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 3s 27ms/step - loss: 0.6201 - acc: 0.8728 - val_loss: 0.8576 - val_acc: 0.8506\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.6136 - acc: 0.8732 - val_loss: 0.8525 - val_acc: 0.8514\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.6014 - acc: 0.8753 - val_loss: 0.8489 - val_acc: 0.8520\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.5906 - acc: 0.8762 - val_loss: 0.8436 - val_acc: 0.8527\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.5796 - acc: 0.8777 - val_loss: 0.8391 - val_acc: 0.8533\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.5682 - acc: 0.8795 - val_loss: 0.8349 - val_acc: 0.8534\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.5613 - acc: 0.8805 - val_loss: 0.8320 - val_acc: 0.8534\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.5509 - acc: 0.8814 - val_loss: 0.8275 - val_acc: 0.8548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2427be1a088>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=256, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c86c1",
   "metadata": {},
   "source": [
    "# 번역기 작동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d74305a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:10:48.515652Z",
     "start_time": "2022-07-21T15:10:48.302800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# 디코더 설계 시작\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단어 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# 수정된 디코더\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9bc03bdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:10:48.623886Z",
     "start_time": "2022-07-21T15:10:48.607879Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] +\n",
    "                                                    states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0cdc0a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:10:49.112499Z",
     "start_time": "2022-07-21T15:10:49.099496Z"
    }
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_src(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if (encoded_word != 0):\n",
    "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "    return sentence\n",
    "\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_tar(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if (encoded_word != 0 and encoded_word != tar_to_index['<sos>']\n",
    "                and encoded_word != tar_to_index['<eos>']):\n",
    "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09ef972f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:10:49.862419Z",
     "start_time": "2022-07-21T15:10:49.851098Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "97e4e8b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:17:19.527032Z",
     "start_time": "2022-07-21T15:17:19.520041Z"
    }
   },
   "outputs": [],
   "source": [
    "english = [] # 영어\n",
    "french_ref = [] # 프랑스어 정답\n",
    "french_cand = [] # 프랑스어 기계번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5473e69f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:22:15.426278Z",
     "start_time": "2022-07-21T15:17:20.075768Z"
    }
   },
   "outputs": [],
   "source": [
    "for seq_index in range(1000):\n",
    "    try:\n",
    "        input_seq = encoder_input_test[seq_index:seq_index + 1]\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "        english.append(seq_to_src(encoder_input_test[seq_index]))\n",
    "        french_ref.append(seq_to_tar(decoder_input_test[seq_index]))\n",
    "        french_cand.append(decoded_sentence[1:-5])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7c359fb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:22:15.442289Z",
     "start_time": "2022-07-21T15:22:15.428280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d0d0ee2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:16:10.384147Z",
     "start_time": "2022-07-21T15:16:10.368143Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"English\":english, \"French_cand\":french_cand, \"French_ref\":french_ref}).to_csv(\"번역결과.csv\", header=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63de72d",
   "metadata": {},
   "source": [
    "# 번역 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4ace440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:16:10.994216Z",
     "start_time": "2022-07-21T15:16:10.984912Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "599aa974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:16:12.051997Z",
     "start_time": "2022-07-21T15:16:12.043683Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"번역결과.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c27bcb6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:16:12.458375Z",
     "start_time": "2022-07-21T15:16:12.440353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French_cand</th>\n",
       "      <th>French_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i already told you .</td>\n",
       "      <td>je vous ai vu ca .</td>\n",
       "      <td>je vous l ai deja dit .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dinner s ready .</td>\n",
       "      <td>la avons la maison .</td>\n",
       "      <td>le diner est pret .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>take care !</td>\n",
       "      <td>prends soin de vous !</td>\n",
       "      <td>prenez soin de vous .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what a team !</td>\n",
       "      <td>comme c est a t il !</td>\n",
       "      <td>quelle equipe !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>did anyone miss me ?</td>\n",
       "      <td>qu est ce que tu a fait mal a l ecole ?</td>\n",
       "      <td>ai je manque a quiconque ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>he fills the bill .</td>\n",
       "      <td>il a l air triste .</td>\n",
       "      <td>il paie l addition .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>tom lies .</td>\n",
       "      <td>tom .</td>\n",
       "      <td>tom ment .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>you re so mean .</td>\n",
       "      <td>vous etes si tu heureux .</td>\n",
       "      <td>vous etes si mechantes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>i m not panicking .</td>\n",
       "      <td>je ne me suis pas naif .</td>\n",
       "      <td>je ne panique pas .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>we re shaken .</td>\n",
       "      <td>nous sommes tous .</td>\n",
       "      <td>nous sommes remues .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   English                               French_cand  \\\n",
       "0    i already told you .                        je vous ai vu ca .    \n",
       "1        dinner s ready .                      la avons la maison .    \n",
       "2             take care !                     prends soin de vous !    \n",
       "3           what a team !                      comme c est a t il !    \n",
       "4    did anyone miss me ?   qu est ce que tu a fait mal a l ecole ?    \n",
       "..                     ...                                       ...   \n",
       "995   he fills the bill .                       il a l air triste .    \n",
       "996            tom lies .                                     tom .    \n",
       "997      you re so mean .                 vous etes si tu heureux .    \n",
       "998   i m not panicking .                  je ne me suis pas naif .    \n",
       "999        we re shaken .                        nous sommes tous .    \n",
       "\n",
       "                      French_ref  \n",
       "0       je vous l ai deja dit .   \n",
       "1           le diner est pret .   \n",
       "2         prenez soin de vous .   \n",
       "3               quelle equipe !   \n",
       "4    ai je manque a quiconque ?   \n",
       "..                           ...  \n",
       "995        il paie l addition .   \n",
       "996                  tom ment .   \n",
       "997    vous etes si mechantes .   \n",
       "998         je ne panique pas .   \n",
       "999        nous sommes remues .   \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d3de0afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:16:13.848298Z",
     "start_time": "2022-07-21T15:16:13.838189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패키지 NLTK의 BLEU : 0.41180376356915777\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "candidate = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "references = [\n",
    "    'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "]\n",
    "\n",
    "print('패키지 NLTK의 BLEU :',bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "980a98b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:16:15.256184Z",
     "start_time": "2022-07-21T15:16:15.111473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\miniconda3\\envs\\deep_tf\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\user\\miniconda3\\envs\\deep_tf\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\user\\miniconda3\\envs\\deep_tf\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "for idx, data in result.iterrows():\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    a = data[\"French_ref\"].split()\n",
    "    temp.append(a)\n",
    "    b = data[\"French_cand\"].split()\n",
    "    temp2.append(b)\n",
    "    score = bleu.sentence_bleu(temp,b)\n",
    "    score_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8258e56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T15:16:15.397028Z",
     "start_time": "2022-07-21T15:16:15.387028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03824374930430969"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(score_list)/len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a245f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
