{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31747f2",
   "metadata": {},
   "source": [
    "# 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80863dd7",
   "metadata": {},
   "source": [
    "## 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1a6d47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:12:25.225472Z",
     "start_time": "2022-07-21T00:12:21.732286Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d4091",
   "metadata": {},
   "source": [
    "## 데이터 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21039d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:12:25.688689Z",
     "start_time": "2022-07-21T00:12:25.227472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 194513\n"
     ]
    }
   ],
   "source": [
    "lines = pd.read_csv(\"D:/Dataset/dataset/parallel_corpus/fra-eng.txt\", names=['src', 'tar', 'lic'], sep='\\t')\n",
    "del lines['lic']\n",
    "print('전체 샘플의 개수 :',len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbf8366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:12:29.817468Z",
     "start_time": "2022-07-21T00:12:29.795462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14683</th>\n",
       "      <td>I'm not leaving.</td>\n",
       "      <td>Je ne m'en vais pas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>It's a fox.</td>\n",
       "      <td>C'est un renard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28428</th>\n",
       "      <td>Don't do that here.</td>\n",
       "      <td>Ne faites pas ça ici.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>I slept late.</td>\n",
       "      <td>J'ai dormi tard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16703</th>\n",
       "      <td>What did you do?</td>\n",
       "      <td>Qu'est-ce que tu as fait ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>Why isn't Tom going?</td>\n",
       "      <td>Pourquoi Tom ne part-il pas ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40982</th>\n",
       "      <td>Glad to see you, Tom.</td>\n",
       "      <td>Content de vous voir, Tom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20522</th>\n",
       "      <td>They grew closer.</td>\n",
       "      <td>Elles se sont approchées.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8666</th>\n",
       "      <td>This is cheap.</td>\n",
       "      <td>C'est bon marché.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13766</th>\n",
       "      <td>How's your foot?</td>\n",
       "      <td>Comment va ton pied ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         src                            tar\n",
       "14683       I'm not leaving.           Je ne m'en vais pas.\n",
       "2199             It's a fox.               C'est un renard.\n",
       "28428    Don't do that here.          Ne faites pas ça ici.\n",
       "5041           I slept late.               J'ai dormi tard.\n",
       "16703       What did you do?     Qu'est-ce que tu as fait ?\n",
       "39640   Why isn't Tom going?  Pourquoi Tom ne part-il pas ?\n",
       "40982  Glad to see you, Tom.     Content de vous voir, Tom.\n",
       "20522      They grew closer.      Elles se sont approchées.\n",
       "8666          This is cheap.              C'est bon marché.\n",
       "13766       How's your foot?          Comment va ton pied ?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[:50000]\n",
    "lines.sample(10) # 샘플"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5cae6",
   "metadata": {},
   "source": [
    "<sos>와 <eos> 대신 '\\t'를 시작 심볼, '\\n'을 종료 심볼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2ac6fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:12:34.654705Z",
     "start_time": "2022-07-21T00:12:34.620655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12405</th>\n",
       "      <td>We volunteered.</td>\n",
       "      <td>\\t Nous nous portâmes volontaires. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28372</th>\n",
       "      <td>Do you want a list?</td>\n",
       "      <td>\\t Voulez-vous une liste ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>Let Tom go.</td>\n",
       "      <td>\\t Laissez Tom partir. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46044</th>\n",
       "      <td>What are you playing?</td>\n",
       "      <td>\\t À quoi jouez-vous ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39448</th>\n",
       "      <td>Where's the airport?</td>\n",
       "      <td>\\t Où se trouve l'aéroport ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22362</th>\n",
       "      <td>Advance two steps.</td>\n",
       "      <td>\\t Avancez de deux pas. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>I giggled.</td>\n",
       "      <td>\\t J'ai gloussé. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Help Tom.</td>\n",
       "      <td>\\t Aidez Tom ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32677</th>\n",
       "      <td>We can handle that.</td>\n",
       "      <td>\\t Nous pouvons nous en débrouiller. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31667</th>\n",
       "      <td>The house is white.</td>\n",
       "      <td>\\t La maison est blanche. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         src                                      tar\n",
       "12405        We volunteered.    \\t Nous nous portâmes volontaires. \\n\n",
       "28372    Do you want a list?            \\t Voulez-vous une liste ? \\n\n",
       "2263             Let Tom go.                \\t Laissez Tom partir. \\n\n",
       "46044  What are you playing?                \\t À quoi jouez-vous ? \\n\n",
       "39448   Where's the airport?          \\t Où se trouve l'aéroport ? \\n\n",
       "22362     Advance two steps.               \\t Avancez de deux pas. \\n\n",
       "1033              I giggled.                      \\t J'ai gloussé. \\n\n",
       "577                Help Tom.                        \\t Aidez Tom ! \\n\n",
       "32677    We can handle that.  \\t Nous pouvons nous en débrouiller. \\n\n",
       "31667    The house is white.             \\t La maison est blanche. \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80097a8",
   "metadata": {},
   "source": [
    "# 문자 수준의 기계 번역기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b80018",
   "metadata": {},
   "source": [
    "## 문자별 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b6d969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:12:42.405445Z",
     "start_time": "2022-07-21T00:12:42.252500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 문자 집합 구축\n",
    "src_vocab = set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 문자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f407cfcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:12:42.563724Z",
     "start_time": "2022-07-21T00:12:42.547821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 char 집합 : 79\n",
      "target 문장의 char 집합 : 103\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print('source 문장의 char 집합 :',src_vocab_size)\n",
    "print('target 문장의 char 집합 :',tar_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db54183",
   "metadata": {},
   "source": [
    "* 각각 영어와 프랑스어에는 91, 115개의 문자가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30182e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:12:46.373434Z",
     "start_time": "2022-07-21T00:12:46.355430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['T', 'U', 'V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8618dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:12:46.530666Z",
     "start_time": "2022-07-21T00:12:46.523664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, '\\u2009': 99, '‘': 100, '’': 101, '\\u202f': 102}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7392d8",
   "metadata": {},
   "source": [
    "* 정렬하여 순서를 정해준뒤 임의로 Index 를 부여하였음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5f46d",
   "metadata": {},
   "source": [
    "## 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717ffc4",
   "metadata": {},
   "source": [
    "### 인코더 인풋의 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb6908b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:12:50.602306Z",
     "start_time": "2022-07-21T00:12:50.515286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "\n",
    "# 1개의 문장\n",
    "for line in lines.src:\n",
    "    encoded_line = []\n",
    "    # 각 줄에서 1개의 char\n",
    "    for char in line:\n",
    "        # 각 char을 정수로 변환\n",
    "        encoded_line.append(src_to_index[char])\n",
    "    encoder_input.append(encoded_line)\n",
    "print('source 문장의 정수 인코딩 :', encoder_input[:5]) # 샘플 5개 문장 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d61ffc",
   "metadata": {},
   "source": [
    "### 디코더 인풋의 정수 인코딩\n",
    "* 교사 강요를 위한 디코더 인풋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16a8801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:13:01.812150Z",
     "start_time": "2022-07-21T00:13:01.596101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 문장의 정수 인코딩 : [[1, 3, 48, 52, 3, 4, 3, 2], [1, 3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [1, 3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [1, 3, 45, 52, 63, 72, 71, 3, 4, 3, 2], [1, 3, 45, 52, 63, 72, 71, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        encoded_line.append(tar_to_index[char])\n",
    "    decoder_input.append(encoded_line)\n",
    "print('target 문장의 정수 인코딩 :', decoder_input[:5]) # 샘플 5개 문장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23a12f",
   "metadata": {},
   "source": [
    "### 디코터 아웃풋의 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f756af3",
   "metadata": {},
   "source": [
    "디코더의 아웃풋에는 <sos> 문장의 시작점이 필요가 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ce55b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:13:30.062065Z",
     "start_time": "2022-07-21T00:13:29.883024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 문장 레이블의 정수 인코딩 : [[3, 48, 52, 3, 4, 3, 2], [3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [3, 45, 52, 63, 72, 71, 3, 4, 3, 2], [3, 45, 52, 63, 72, 71, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    timestep = 0\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        if timestep > 0:\n",
    "            encoded_line.append(tar_to_index[char])\n",
    "        timestep = timestep + 1\n",
    "    decoder_target.append(encoded_line)\n",
    "print('target 문장 레이블의 정수 인코딩 :', decoder_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cc22d9",
   "metadata": {},
   "source": [
    "## 패딩과 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b5d048",
   "metadata": {},
   "source": [
    "각 문장의 최대길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cbcaea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:13:30.938778Z",
     "start_time": "2022-07-21T00:13:30.923784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 최대 길이 : 22\n",
      "target 문장의 최대 길이 : 76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print('source 문장의 최대 길이 :',max_src_len)\n",
    "print('target 문장의 최대 길이 :',max_tar_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3f49d",
   "metadata": {},
   "source": [
    "* 최대 길이에 맞게 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bec52188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:13:36.765183Z",
     "start_time": "2022-07-21T00:13:36.203997Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d580a",
   "metadata": {},
   "source": [
    "* 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b881f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:13:49.079849Z",
     "start_time": "2022-07-21T00:13:48.781336Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b13ebd",
   "metadata": {},
   "source": [
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb9bd488",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:13:51.434764Z",
     "start_time": "2022-07-21T00:13:49.948236Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "\n",
    "# encoder_outputs은 여기서는 불필요\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "512ba8ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:14:00.773589Z",
     "start_time": "2022-07-21T00:14:00.524533Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "\n",
    "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d50b42e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:18:13.120026Z",
     "start_time": "2022-07-21T00:14:10.492968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "313/313 [==============================] - 15s 22ms/step - loss: 1.2546 - val_loss: 0.7791\n",
      "Epoch 2/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.5779 - val_loss: 0.6465\n",
      "Epoch 3/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4747 - val_loss: 0.5632\n",
      "Epoch 4/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.4206 - val_loss: 0.5096\n",
      "Epoch 5/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3796 - val_loss: 0.4787\n",
      "Epoch 6/40\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3506 - val_loss: 0.4485\n",
      "Epoch 7/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3269 - val_loss: 0.4280\n",
      "Epoch 8/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3096 - val_loss: 0.4143\n",
      "Epoch 9/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2944 - val_loss: 0.4010\n",
      "Epoch 10/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2816 - val_loss: 0.3895\n",
      "Epoch 11/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2693 - val_loss: 0.3836\n",
      "Epoch 12/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2602 - val_loss: 0.3788\n",
      "Epoch 13/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2514 - val_loss: 0.3704\n",
      "Epoch 14/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2428 - val_loss: 0.3700\n",
      "Epoch 15/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2354 - val_loss: 0.3632\n",
      "Epoch 16/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2288 - val_loss: 0.3636\n",
      "Epoch 17/40\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2233 - val_loss: 0.3581\n",
      "Epoch 18/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2174 - val_loss: 0.3584\n",
      "Epoch 19/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2118 - val_loss: 0.3554\n",
      "Epoch 20/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2060 - val_loss: 0.3537\n",
      "Epoch 21/40\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2022 - val_loss: 0.3562\n",
      "Epoch 22/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1969 - val_loss: 0.3546\n",
      "Epoch 23/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1940 - val_loss: 0.3562\n",
      "Epoch 24/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1892 - val_loss: 0.3576\n",
      "Epoch 25/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1855 - val_loss: 0.3578\n",
      "Epoch 26/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1815 - val_loss: 0.3577\n",
      "Epoch 27/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1788 - val_loss: 0.3604\n",
      "Epoch 28/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1754 - val_loss: 0.3615\n",
      "Epoch 29/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1719 - val_loss: 0.3614\n",
      "Epoch 30/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1687 - val_loss: 0.3626\n",
      "Epoch 31/40\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.1658 - val_loss: 0.3630\n",
      "Epoch 32/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1628 - val_loss: 0.3675\n",
      "Epoch 33/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1603 - val_loss: 0.3674\n",
      "Epoch 34/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1580 - val_loss: 0.3716\n",
      "Epoch 35/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1552 - val_loss: 0.3717\n",
      "Epoch 36/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1524 - val_loss: 0.3746\n",
      "Epoch 37/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1499 - val_loss: 0.3780\n",
      "Epoch 38/40\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1474 - val_loss: 0.3828\n",
      "Epoch 39/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1460 - val_loss: 0.3835\n",
      "Epoch 40/40\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1431 - val_loss: 0.3879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2069ab03588>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=128, epochs=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb718206",
   "metadata": {},
   "source": [
    "## 번역기 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cecedea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:18:21.701938Z",
     "start_time": "2022-07-21T00:18:21.684935Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4acf5fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:18:22.240510Z",
     "start_time": "2022-07-21T00:18:21.836791Z"
    }
   },
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
    "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fef5ba19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:18:22.713912Z",
     "start_time": "2022-07-21T00:18:22.708911Z"
    }
   },
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f531d614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:18:22.872933Z",
     "start_time": "2022-07-21T00:18:22.853928Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] +\n",
    "                                                    states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06288bb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T00:18:44.392964Z",
     "start_time": "2022-07-21T00:18:41.198456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Go.\n",
      "정답 문장: Marche. \n",
      "번역 문장: Bouge ! \n",
      "-----------------------------------\n",
      "입력 문장: Run.\n",
      "정답 문장: Fuyons ! \n",
      "번역 문장: Cours ! \n",
      "-----------------------------------\n",
      "입력 문장: Help me!\n",
      "정답 문장: Aide-moi ! \n",
      "번역 문장: Attendez à Tom. \n",
      "-----------------------------------\n",
      "입력 문장: I did it.\n",
      "정답 문장: Je l'ai fait. \n",
      "번역 문장: Je l'ai fait du café. \n",
      "-----------------------------------\n",
      "입력 문장: Humor Tom.\n",
      "정답 문장: Mettez Tom de bonne humeur. \n",
      "번역 문장: Serre-moi. \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [1,20,300,600,1001]:  # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index:seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index]) -\n",
    "                                         1])  # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역 문장:',\n",
    "          decoded_sentence[1:len(decoded_sentence) - 1])  # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8ea1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
